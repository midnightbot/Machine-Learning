{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4915 - acc: 0.8272\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.3710 - acc: 0.8656\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.3353 - acc: 0.8785\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.3100 - acc: 0.8859\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2933 - acc: 0.8916\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 0.3438 - acc: 0.8763\n"
     ]
    }
   ],
   "source": [
    "#HERE WE USE THE NORMAL NEURAL NETWORK MODEL\n",
    "# SEE THE ACCURACY\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images / 255.0\n",
    "test_images=test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE THE ABOVE ACCURACY FOR TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW WE WILL USE CONVOLUTIONAL NEURAL NTWK\n",
    "#IN NEURAL NTWK WE SEE EACH AND EVERY PIXEL AND TRY TO SAY WHETHER IT IS A SHOE OR A BAG OR ETC\n",
    "#IN CONVNETS WE TRY TO FIND FEATURES THAT MAKE SHOE A SHOE RATHER THAN LOOKING AT EACH PIXEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 0.4350 - acc: 0.8416\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 29s 477us/sample - loss: 0.2927 - acc: 0.8933 - lo\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 27s 458us/sample - loss: 0.2455 - acc: 0.9090\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 28s 459us/sample - loss: 0.2137 - acc: 0.9209\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 0.1885 - acc: 0.9286\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.2476 - acc: 0.9136\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS SEEN FROM ABOVE BY USING THE CONVNET THE ACCURACY IS HIGHER THAN IN NORMAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Explaining the above layers</font>\n",
    "<img src = 'attachments/convnet_exp.JPG'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the convolutions and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[0,x].grid(False)\n",
    "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[1,x].grid(False)\n",
    "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "  axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
